{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basics first\n",
    "\n",
    "\n",
    "\n",
    "Pandas is built around two data structures: \n",
    "    - pandas.Series\n",
    "    - pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    3.0\n",
      "2    5.0\n",
      "3    NaN\n",
      "4    6.0\n",
      "5    8.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A Series is a list with labels that can hold any data type\n",
    "## from 10 minutes to pandas (https://pandas.pydata.org/pandas-docs/stable/10min.html#min)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1,3,5,np.nan,6,8])\n",
    "print(s)\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
      "               '2013-01-05', '2013-01-06'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "                   A         B         C         D\n",
      "2013-01-01  0.079434  1.274149  1.420693 -0.892609\n",
      "2013-01-02  0.078154 -0.965840 -2.512529 -1.074411\n",
      "2013-01-03 -0.469473 -0.316255  0.729341 -0.063086\n",
      "2013-01-04  0.292487  1.554517  1.624547 -0.455047\n",
      "2013-01-05 -1.577646 -1.104378 -0.255310  0.216365\n",
      "2013-01-06  0.279195 -0.048132 -1.488238  0.049494\n",
      "\n",
      "2013-01-01    0.079434\n",
      "2013-01-02    0.078154\n",
      "2013-01-03   -0.469473\n",
      "2013-01-04    0.292487\n",
      "2013-01-05   -1.577646\n",
      "2013-01-06    0.279195\n",
      "Freq: D, Name: A, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## A DataFrame is a two-dimensional labeled data structure that can be subset into Series objects\n",
    "## from 10 minutes to pandas\n",
    "\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "print(dates)\n",
    "df    = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "print(df)\n",
    "print()\n",
    "print(df.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file     = \"./10900_Invers_ScanResults.txt\"\n",
    "outDir   = \"./SumStatsVecs\"\n",
    "\n",
    "stats = [\"Hscan_v1.3_H12\", \"pcadapt_3.0.4_ALL_log10p\", \"OutFLANK_0.2_He\", \"LFMM_ridge_0.0_ALL_log10p\",\n",
    "        \"LFMM_lasso_0.0_ALL_log10p\", \"rehh_2.0.2_ALL_log10p\", \"Spearmans_ALL_rho\", \"a_freq_final\", \n",
    "        \"pcadapt_3.0.4_PRUNED_log10p\"]\n",
    "\n",
    "!mkdir -p $outDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : \n",
    "### Turn '10900_Invers_ScanResults.txt' into a set of 12 feature vectors, one for each class\n",
    "\n",
    "## Steps:\n",
    "1) Read the text file into a dataframe\n",
    "\n",
    "2) Scale all the statistics\n",
    "\n",
    "3) Label each SNP based on region and muttype\n",
    "\n",
    "4) Split the dataframe based on label and print each class to its own file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the text file into a dataframe\n",
    "\n",
    "Pandas has a few convenient function for reading in text files:\n",
    "\n",
    "`df = pd.read_csv(filepath, sep, header,...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vcf_ord  pos  chrom  a_freq_old muttype            unique  for_relatedness  \\\n",
      "0        1   62      1      0.3005    MT=1   10900_62_MT=1_1             True   \n",
      "1        4  392      1      0.2035    MT=1  10900_392_MT=1_4            False   \n",
      "2        6  445      1      0.0720    MT=1  10900_445_MT=1_6            False   \n",
      "\n",
      "   a_freq_final  keep_loci  simID ... rehh_2.0.2_ALL_iHS  \\\n",
      "0      0.299197       True  10900 ...                NaN   \n",
      "1      0.203313       True  10900 ...                NaN   \n",
      "2      0.072289       True  10900 ...                NaN   \n",
      "\n",
      "   rehh_2.0.2_ALL_log10p  Spearmans_ALL_rho  selCoef  originGen  freq_old  \\\n",
      "0                    NaN           0.050616      NaN        NaN       NaN   \n",
      "1                    NaN          -0.025850      NaN        NaN       NaN   \n",
      "2                    NaN          -0.031636      NaN        NaN       NaN   \n",
      "\n",
      "   freq_final  pa2  prop  He  \n",
      "0         NaN  NaN   NaN NaN  \n",
      "1         NaN  NaN   NaN NaN  \n",
      "2         NaN  NaN   NaN NaN  \n",
      "\n",
      "[3 rows x 37 columns]\n",
      "(6927, 37)\n",
      "Index(['vcf_ord', 'pos', 'chrom', 'a_freq_old', 'muttype', 'unique',\n",
      "       'for_relatedness', 'a_freq_final', 'keep_loci', 'simID', 'quasi_indep',\n",
      "       'Hscan_v1.3_H12', 'pca_ALL_PC1_loadings', 'pca_ALL_PC2_loadings',\n",
      "       'pca_ALL_PC3_loadings', 'pca_PRUNED_PC1_loadings',\n",
      "       'pca_PRUNED_PC2_loadings', 'pcadapt_3.0.4_ALL_chisq',\n",
      "       'pcadapt_3.0.4_ALL_log10p', 'pcadapt_3.0.4_PRUNED_log10p',\n",
      "       'OutFLANK_0.2_FST', 'OutFLANK_0.2_He', 'OutFLANK_0.2_ALL_log10p',\n",
      "       'OutFLANK_0.2_PRUNED_log10p', 'LFMM_ridge_0.0_ALL_log10p',\n",
      "       'LFMM_lasso_0.0_ALL_log10p', 'CHR', 'rehh_2.0.2_ALL_iHS',\n",
      "       'rehh_2.0.2_ALL_log10p', 'Spearmans_ALL_rho', 'selCoef', 'originGen',\n",
      "       'freq_old', 'freq_final', 'pa2', 'prop', 'He'],\n",
      "      dtype='object')\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "5        1\n",
      "6        1\n",
      "7        1\n",
      "8        1\n",
      "9        1\n",
      "10       1\n",
      "11       1\n",
      "12       1\n",
      "13       1\n",
      "14       1\n",
      "15       1\n",
      "16       1\n",
      "17       1\n",
      "18       1\n",
      "19       1\n",
      "20       1\n",
      "21       1\n",
      "22       1\n",
      "23       1\n",
      "24       1\n",
      "25       1\n",
      "26       1\n",
      "27       1\n",
      "28       1\n",
      "29       1\n",
      "        ..\n",
      "6897    10\n",
      "6898    10\n",
      "6899    10\n",
      "6900    10\n",
      "6901    10\n",
      "6902    10\n",
      "6903    10\n",
      "6904    10\n",
      "6905    10\n",
      "6906    10\n",
      "6907    10\n",
      "6908    10\n",
      "6909    10\n",
      "6910    10\n",
      "6911    10\n",
      "6912    10\n",
      "6913    10\n",
      "6914    10\n",
      "6915    10\n",
      "6916    10\n",
      "6917    10\n",
      "6918    10\n",
      "6919    10\n",
      "6920    10\n",
      "6921    10\n",
      "6922    10\n",
      "6923    10\n",
      "6924    10\n",
      "6925    10\n",
      "6926    10\n",
      "Name: chrom, Length: 6927, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Did the file get read correctly?\n",
    "featDf = pd.read_csv(file, sep = \" \")\n",
    "\n",
    "print(featDf.head(3))\n",
    "print(featDf.shape)\n",
    "print(featDf.columns)\n",
    "print(featDf.chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6909, 37)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The data has a 'keep_loci' column, saying whether an SNP passed the filters or not. We should get rid of the\n",
    "## SNPs that didn't pass\n",
    "featDf = featDf[featDf['keep_loci'] == True]\n",
    "featDf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'group_by' function\n",
    "\n",
    "`DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)`\n",
    "\n",
    "group_by is a very useful function. You can call it on your dataframe with a function or label to group it by to get a group_by object that consists of the dataframe split up into different dataframes based on the function or label. You can access groups with get_group:\n",
    "\n",
    "`GroupBy.get_group(name, obj=None)`\n",
    "\n",
    "name is the name of the group, obj is the group_by object to take it from (default is the object it was called on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop function\n",
    "\n",
    "`DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')`\n",
    "\n",
    "You can call .drop on a datframe to remove data from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6220, 37)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SNPs on chromosome 9 have variable recombination, meaning this \n",
    "## chromosome is not the same in every simulation and it is hard to\n",
    "## classify. How can we just remove this from our data?\n",
    "\n",
    "## The group_by() function is well suited to the task\n",
    "grouped  = featDf.groupby('chrom')\n",
    "features = featDf.drop(grouped.get_group(9).index)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the statistics\n",
    "\n",
    "Machine learning features should be scaled before they are given to a classifier. In this case, the scaling we want to do works like this: \n",
    "\n",
    "Take the statistic in one column. If it is negative at any of the SNPs, add the smallest value of the statistic to every value in the column. Now, take the sum of the column and divide each value in the column by that sum. Repeat for each column\n",
    "\n",
    "All features are now between 0 and 1.\n",
    "\n",
    "I'll give you a scale stats function I wrote to do the math with a single column, but we have to figure out how to scale every column with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleStats(statSeries):\n",
    "    #### some of the values for pcadaptlog10p were 'Inf'. This breaks some of the math, so I replaced the values\n",
    "    #### with a very large log10p value of 400, which represents an p-value extremely close to 0 and lower than \n",
    "    #### any of the non-Inf p-values\n",
    "    statSeries.replace('Inf', 400, inplace = True)\n",
    "    statSeries = pd.to_numeric(statSeries, errors = 'coerce')\n",
    "    \n",
    "    # if there are any negative values, scale by addition first\n",
    "    minStat = statSeries.min()\n",
    "    if minStat < 0: \n",
    "        statSeries = statSeries + minStat\n",
    "    \n",
    "    # scale by dividing values by the sum\n",
    "    if statSeries.sum() != 0: \n",
    "        return(statSeries.divide(statSeries.sum(), fill_value = 0))\n",
    "    else:\n",
    "        return(statSeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The apply function\n",
    "\n",
    "`DataFrame.apply(func, axis=0, broadcast=None, raw=False, reduce=None, result_type=None, args=(), **kwds)`\n",
    "\n",
    "func -- function to apply\n",
    "\n",
    "axis = 0 applies by column, axis = 1 applies by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hscan_v1.3_H12</th>\n",
       "      <th>pcadapt_3.0.4_ALL_log10p</th>\n",
       "      <th>OutFLANK_0.2_He</th>\n",
       "      <th>LFMM_ridge_0.0_ALL_log10p</th>\n",
       "      <th>LFMM_lasso_0.0_ALL_log10p</th>\n",
       "      <th>rehh_2.0.2_ALL_log10p</th>\n",
       "      <th>Spearmans_ALL_rho</th>\n",
       "      <th>a_freq_final</th>\n",
       "      <th>pcadapt_3.0.4_PRUNED_log10p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hscan_v1.3_H12  pcadapt_3.0.4_ALL_log10p  OutFLANK_0.2_He  \\\n",
       "0             0.0                       0.0         0.000313   \n",
       "1             0.0                       0.0         0.000242   \n",
       "2             0.0                       0.0         0.000100   \n",
       "3             0.0                       0.0         0.000017   \n",
       "4             0.0                       0.0         0.000022   \n",
       "\n",
       "   LFMM_ridge_0.0_ALL_log10p  LFMM_lasso_0.0_ALL_log10p  \\\n",
       "0                   0.000121                   0.000008   \n",
       "1                   0.000142                   0.000120   \n",
       "2                   0.000089                   0.000040   \n",
       "3                   0.000085                   0.000312   \n",
       "4                   0.000533                   0.000178   \n",
       "\n",
       "   rehh_2.0.2_ALL_log10p  Spearmans_ALL_rho  a_freq_final  \\\n",
       "0                    0.0           0.000137      0.000223   \n",
       "1                    0.0           0.000172      0.000151   \n",
       "2                    0.0           0.000175      0.000054   \n",
       "3                    0.0           0.000136      0.000009   \n",
       "4                    0.0           0.000223      0.000011   \n",
       "\n",
       "   pcadapt_3.0.4_PRUNED_log10p  \n",
       "0                     0.000201  \n",
       "1                     0.000061  \n",
       "2                     0.000083  \n",
       "3                     0.000020  \n",
       "4                     0.000516  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How can we scale every without using a loop (too slow)?\n",
    "## Scaling columns such as 'chrom' or 'pos' doesn't make sense, how do we only scale the columns we want?\n",
    "\n",
    "## The 'apply' function allows us to do it in a single line\n",
    "scaledFeatures = features[stats].apply(scaleStats, axis = 0)\n",
    "scaledFeatures.shape\n",
    "scaledFeatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label the SNPs\n",
    "\n",
    "The snps are labeled based on their position and their muttype. We can easily write a function to take a SNPs position and muttype and return a label, but how can we 'apply' this function if it takes variables in two different columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of Labels\n",
    "\n",
    "possible muttypes:\n",
    "\n",
    " - neutral\n",
    " - QTN         : can be either large effect (>.20 of variation in phenotype) or small effect (<.20 of variation)\n",
    " - deleterious : mutation that negatively effects fitness\n",
    " - sweep       : mutation that has become fixed and is expected to show evidence of a selective sweep around it\n",
    "\n",
    "possible regions:\n",
    "\n",
    " - Background selection : any SNP in the 10,000bp region where deleterious mutations occurred \n",
    " - Near Selective Sweep : within 1,000bp of the selective sweep\n",
    " - Far Selective Sweep  : 1,000-2,000bp from the selective sweep\n",
    " - large QTN linked     : within 200bp of a QTN of large effect\n",
    " - small QTN linked     : within 200bp of a QTN of small effect\n",
    " - inversion            : in an inversion\n",
    " - low recombination    : in a region of low recombination\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLabel(statSeries):\n",
    "    pos     = statSeries['pos']\n",
    "    muttype = statSeries['muttype']\n",
    "    # 1 = neut, 2 = QTN, 3 = delet, 4 = sweep\n",
    "    muttypes = {\"MT=1\" : \"neut\", \n",
    "                \"MT=2\" : \"QTN\",\n",
    "                \"MT=3\" : \"delet\",\n",
    "                \"MT=4\" : \"sweep\",\n",
    "                \"MT=5\" : \"neut\"}         ### MT=5 is a artifact from SLiM to preserve the inversion\n",
    "    try:\n",
    "        mtLabel = muttypes[muttype]\n",
    "    except KeyError:\n",
    "        warnings.warn(\"Unknown muttype \" + muttype)\n",
    "        mtLabel = \"INVALID\"\n",
    "    \n",
    "    pos = float(pos)\n",
    "    if  200001 <= pos <= 230000 or  270001 <= pos <= 280000:\n",
    "        region = \"BS\"\n",
    "    elif 174000 <= pos <= 176000:\n",
    "        region = \"NearSS\"\n",
    "    elif 173000 <= pos <= 17399 or 176001 <= pos <= 177000:\n",
    "        region = \"FarSS\"\n",
    "    elif 320000 <= pos <= 330000:\n",
    "        region = \"invers\"\n",
    "    elif 370000 <= pos <= 380000:\n",
    "        region = \"lowRC\"\n",
    "    else:\n",
    "        region = \"neutral\"\n",
    "    return \"MT=\" + mtLabel + \"_R=\" + region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'insert' function\n",
    "\n",
    "`DataFrame.insert(loc, column, value, allow_duplicates=False)`\n",
    "\n",
    "Pretty simple function that inserts the 'value' at the given 'loc' and names the new column 'column'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6220, 10)\n",
      "          classLabel  Hscan_v1.3_H12  pcadapt_3.0.4_ALL_log10p  \\\n",
      "0  MT=neut_R=neutral             0.0                       0.0   \n",
      "1  MT=neut_R=neutral             0.0                       0.0   \n",
      "2  MT=neut_R=neutral             0.0                       0.0   \n",
      "3  MT=neut_R=neutral             0.0                       0.0   \n",
      "4  MT=neut_R=neutral             0.0                       0.0   \n",
      "\n",
      "   OutFLANK_0.2_He  LFMM_ridge_0.0_ALL_log10p  LFMM_lasso_0.0_ALL_log10p  \\\n",
      "0         0.000313                   0.000121                   0.000008   \n",
      "1         0.000242                   0.000142                   0.000120   \n",
      "2         0.000100                   0.000089                   0.000040   \n",
      "3         0.000017                   0.000085                   0.000312   \n",
      "4         0.000022                   0.000533                   0.000178   \n",
      "\n",
      "   rehh_2.0.2_ALL_log10p  Spearmans_ALL_rho  a_freq_final  \\\n",
      "0                    0.0           0.000137      0.000223   \n",
      "1                    0.0           0.000172      0.000151   \n",
      "2                    0.0           0.000175      0.000054   \n",
      "3                    0.0           0.000136      0.000009   \n",
      "4                    0.0           0.000223      0.000011   \n",
      "\n",
      "   pcadapt_3.0.4_PRUNED_log10p  \n",
      "0                     0.000201  \n",
      "1                     0.000061  \n",
      "2                     0.000083  \n",
      "3                     0.000020  \n",
      "4                     0.000516  \n"
     ]
    }
   ],
   "source": [
    "## What's the best way to apply a function to two columns of a data frame?\n",
    "\n",
    "## Answer from stack overflow:\n",
    "## rewrite the function to take a pandas series. Apply the function row wise\n",
    "## (https://stackoverflow.com/questions/13331698/how-to-apply-a-function-to-two-columns-of-pandas-dataframe)\n",
    "scaledFeatures.insert(loc = 0, column = 'classLabel', value = features.apply(findLabel, axis = 1))\n",
    "\n",
    "print(scaledFeatures.shape)\n",
    "print(scaledFeatures.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we need to add some more labels -- MT=2 means a QTN but does not distinguish between large and small QTNS\n",
    "## In addition, there is no muttype for 'linked to a large QTN'. We are going to need the position column to \n",
    "# locate the linked alleles and the proportion column to differentiate the large and small QTNs\n",
    "\n",
    "\n",
    "# add pos and prop back in to locate QTNs of large and small effect\n",
    "scaledFeatures.insert(loc = 0, column = 'pos', value = features['pos'].astype(\"float\"))\n",
    "scaledFeatures.insert(loc = 0, column = 'prop', value = pd.to_numeric(features['prop'], errors = \"coerce\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loc function:\n",
    "\n",
    "`DataFrame.loc[]`\n",
    "\n",
    "loc accesses a group of rows or columns directly from a dataframe. You can modify the loc object directly, it is not a copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 'isin' function\n",
    "\n",
    "`DataFrame.isin(values)`\n",
    "\n",
    "Returns a boolean DataFrame showing whether each element in the dataframe is contained in values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1352     97770.0\n",
      "1797    129593.0\n",
      "Name: pos, dtype: float64\n",
      "703      52646.0\n",
      "1031     76234.0\n",
      "1045     77280.0\n",
      "1171     86468.0\n",
      "1211     89806.0\n",
      "1316     95858.0\n",
      "1499    107652.0\n",
      "1952    139941.0\n",
      "Name: pos, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Now that we have the proportions, we need to actually filter through them find the large and small QTNs\n",
    "## The rule is, < 20 % proportion is a small QTN and > 20% proportion is a large QTN. This only applies to \n",
    "## SNPs marked as QTNs in the first place.\n",
    "\n",
    "## We can do this with no additional functions, just some more complicated subsetting\n",
    "## get the positions of SNPs where the classLabel is MT=QTN_R=neutral and the prop is < 0.20\n",
    "smallQTNs = scaledFeatures[((scaledFeatures.classLabel == 'MT=QTN_R=neutral') & \n",
    "                            (scaledFeatures.prop < 0.20))]['pos']\n",
    "largeQTNs = scaledFeatures[((scaledFeatures.classLabel == 'MT=QTN_R=neutral') & \n",
    "                            (scaledFeatures.prop >= 0.20))]['pos']\n",
    "\n",
    "print(largeQTNs)\n",
    "print(smallQTNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         prop       pos            classLabel  Hscan_v1.3_H12  \\\n",
      "703   0.01108   52646.0  MT=smQTN_R=smQTNlink        0.000129   \n",
      "1031  0.07953   76234.0  MT=smQTN_R=smQTNlink        0.000150   \n",
      "1045  0.02989   77280.0  MT=smQTN_R=smQTNlink        0.000230   \n",
      "1171  0.09379   86468.0  MT=smQTN_R=smQTNlink        0.000203   \n",
      "1211  0.05882   89806.0  MT=smQTN_R=smQTNlink        0.000117   \n",
      "1316  0.00016   95858.0  MT=smQTN_R=smQTNlink        0.000076   \n",
      "1499  0.00207  107652.0  MT=smQTN_R=smQTNlink        0.000118   \n",
      "1952  0.01375  139941.0  MT=smQTN_R=smQTNlink        0.000201   \n",
      "\n",
      "      pcadapt_3.0.4_ALL_log10p  OutFLANK_0.2_He  LFMM_ridge_0.0_ALL_log10p  \\\n",
      "703                        0.0         0.000079                   0.000520   \n",
      "1031                       0.0         0.000147                   0.005108   \n",
      "1045                       0.0         0.000373                   0.002201   \n",
      "1171                       0.0         0.000207                   0.004740   \n",
      "1211                       0.0         0.000373                   0.001623   \n",
      "1316                       0.0         0.000315                   0.000116   \n",
      "1499                       0.0         0.000076                   0.000448   \n",
      "1952                       0.0         0.000019                   0.000032   \n",
      "\n",
      "      LFMM_lasso_0.0_ALL_log10p  rehh_2.0.2_ALL_log10p  Spearmans_ALL_rho  \\\n",
      "703                    0.000591               0.000000           0.000213   \n",
      "1031                   0.003533               0.000098           0.000310   \n",
      "1045                   0.001983               0.000154           0.000086   \n",
      "1171                   0.004654               0.000249           0.000296   \n",
      "1211                   0.001382               0.000035           0.000245   \n",
      "1316                   0.000034               0.000868           0.000141   \n",
      "1499                   0.000415               0.000453           0.000151   \n",
      "1952                   0.000076               0.000000           0.000134   \n",
      "\n",
      "      a_freq_final  pcadapt_3.0.4_PRUNED_log10p  \n",
      "703       0.000703                     0.000292  \n",
      "1031      0.000082                     0.003113  \n",
      "1045      0.000365                     0.001075  \n",
      "1171      0.000124                     0.002222  \n",
      "1211      0.000376                     0.000967  \n",
      "1316      0.000225                     0.000120  \n",
      "1499      0.000040                     0.000234  \n",
      "1952      0.000010                     0.000042  \n"
     ]
    }
   ],
   "source": [
    "## update the labels --  use the 'loc' function and the 'isin' function\n",
    "## loc function avoids chain indexing, which is important when setting values in the dataframe\n",
    "scaledFeatures.loc[scaledFeatures['pos'].isin(largeQTNs), 'classLabel'] = 'MT=lgQTN_R=lgQTNlink'\n",
    "scaledFeatures.loc[scaledFeatures['pos'].isin(smallQTNs), 'classLabel'] = 'MT=smQTN_R=smQTNlink'\n",
    "\n",
    "print(scaledFeatures[scaledFeatures.pos.isin(smallQTNs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'between' function\n",
    "\n",
    "`Series.between(left, right, inclusive=True)`\n",
    "\n",
    "Takes a series, returns a boolean series indicating whether each element in the series is between 'left' and 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prop       pos           classLabel  Hscan_v1.3_H12  \\\n",
      "700    NaN   52468.0  MT=neut_R=smQTNlink        0.000137   \n",
      "701    NaN   52550.0  MT=neut_R=smQTNlink        0.000130   \n",
      "702    NaN   52635.0  MT=neut_R=smQTNlink        0.000131   \n",
      "704    NaN   52763.0  MT=neut_R=smQTNlink        0.000154   \n",
      "705    NaN   52835.0  MT=neut_R=smQTNlink        0.000129   \n",
      "1028   NaN   76099.0  MT=neut_R=smQTNlink        0.000179   \n",
      "1029   NaN   76199.0  MT=neut_R=smQTNlink        0.000162   \n",
      "1030   NaN   76215.0  MT=neut_R=smQTNlink        0.000161   \n",
      "1032   NaN   76267.0  MT=neut_R=smQTNlink        0.000156   \n",
      "1033   NaN   76320.0  MT=neut_R=smQTNlink        0.000152   \n",
      "1034   NaN   76372.0  MT=neut_R=smQTNlink        0.000165   \n",
      "1035   NaN   76411.0  MT=neut_R=smQTNlink        0.000160   \n",
      "1044   NaN   77159.0  MT=neut_R=smQTNlink        0.000186   \n",
      "1046   NaN   77304.0  MT=neut_R=smQTNlink        0.000195   \n",
      "1047   NaN   77416.0  MT=neut_R=smQTNlink        0.000194   \n",
      "1167   NaN   86327.0  MT=neut_R=smQTNlink        0.000149   \n",
      "1168   NaN   86395.0  MT=neut_R=smQTNlink        0.000130   \n",
      "1169   NaN   86421.0  MT=neut_R=smQTNlink        0.000132   \n",
      "1170   NaN   86431.0  MT=neut_R=smQTNlink        0.000180   \n",
      "1172   NaN   86649.0  MT=neut_R=smQTNlink        0.000197   \n",
      "1210   NaN   89714.0  MT=neut_R=smQTNlink        0.000131   \n",
      "1212   NaN   89888.0  MT=neut_R=smQTNlink        0.000096   \n",
      "1213   NaN   89925.0  MT=neut_R=smQTNlink        0.000103   \n",
      "1214   NaN   89943.0  MT=neut_R=smQTNlink        0.000088   \n",
      "1215   NaN   89943.0  MT=neut_R=smQTNlink        0.000088   \n",
      "1216   NaN   89978.0  MT=neut_R=smQTNlink        0.000084   \n",
      "1217   NaN   89995.0  MT=neut_R=smQTNlink        0.000097   \n",
      "1310   NaN   95670.0  MT=neut_R=smQTNlink        0.000137   \n",
      "1311   NaN   95694.0  MT=neut_R=smQTNlink        0.000108   \n",
      "1312   NaN   95728.0  MT=neut_R=smQTNlink        0.000109   \n",
      "1313   NaN   95736.0  MT=neut_R=smQTNlink        0.000101   \n",
      "1314   NaN   95807.0  MT=neut_R=smQTNlink        0.000105   \n",
      "1315   NaN   95853.0  MT=neut_R=smQTNlink        0.000089   \n",
      "1317   NaN   95867.0  MT=neut_R=smQTNlink        0.000078   \n",
      "1318   NaN   95904.0  MT=neut_R=smQTNlink        0.000084   \n",
      "1319   NaN   95920.0  MT=neut_R=smQTNlink        0.000090   \n",
      "1320   NaN   95934.0  MT=neut_R=smQTNlink        0.000084   \n",
      "1321   NaN   95999.0  MT=neut_R=smQTNlink        0.000089   \n",
      "1322   NaN   96013.0  MT=neut_R=smQTNlink        0.000081   \n",
      "1497   NaN  107452.0  MT=neut_R=smQTNlink        0.000139   \n",
      "1498   NaN  107622.0  MT=neut_R=smQTNlink        0.000138   \n",
      "1500   NaN  107726.0  MT=neut_R=smQTNlink        0.000129   \n",
      "1501   NaN  107753.0  MT=neut_R=smQTNlink        0.000140   \n",
      "1502   NaN  107785.0  MT=neut_R=smQTNlink        0.000122   \n",
      "1503   NaN  107796.0  MT=neut_R=smQTNlink        0.000125   \n",
      "1947   NaN  139781.0  MT=neut_R=smQTNlink        0.000157   \n",
      "1948   NaN  139785.0  MT=neut_R=smQTNlink        0.000154   \n",
      "1949   NaN  139791.0  MT=neut_R=smQTNlink        0.000212   \n",
      "1950   NaN  139913.0  MT=neut_R=smQTNlink        0.000198   \n",
      "1951   NaN  139936.0  MT=neut_R=smQTNlink        0.000202   \n",
      "\n",
      "      pcadapt_3.0.4_ALL_log10p  OutFLANK_0.2_He  LFMM_ridge_0.0_ALL_log10p  \\\n",
      "700                        0.0         0.000154                   0.000685   \n",
      "701                        0.0         0.000080                   0.000521   \n",
      "702                        0.0         0.000035                   0.000095   \n",
      "704                        0.0         0.000373                   0.000075   \n",
      "705                        0.0         0.000303                   0.000455   \n",
      "1028                       0.0         0.000195                   0.003323   \n",
      "1029                       0.0         0.000062                   0.000342   \n",
      "1030                       0.0         0.000166                   0.000315   \n",
      "1032                       0.0         0.000090                   0.000123   \n",
      "1033                       0.0         0.000097                   0.000020   \n",
      "1034                       0.0         0.000165                   0.000311   \n",
      "1035                       0.0         0.000211                   0.002839   \n",
      "1044                       0.0         0.000202                   0.000534   \n",
      "1046                       0.0         0.000084                   0.000040   \n",
      "1047                       0.0         0.000035                   0.000136   \n",
      "1167                       0.0         0.000373                   0.000708   \n",
      "1168                       0.0         0.000128                   0.000047   \n",
      "1169                       0.0         0.000053                   0.000167   \n",
      "1170                       0.0         0.000372                   0.001014   \n",
      "1172                       0.0         0.000028                   0.000322   \n",
      "1210                       0.0         0.000258                   0.000092   \n",
      "1212                       0.0         0.000037                   0.000078   \n",
      "1213                       0.0         0.000283                   0.000618   \n",
      "1214                       0.0         0.000258                   0.000081   \n",
      "1215                       0.0         0.000115                   0.000296   \n",
      "1216                       0.0         0.000115                   0.000296   \n",
      "1217                       0.0         0.000340                   0.000337   \n",
      "1310                       0.0         0.000348                   0.000277   \n",
      "1311                       0.0         0.000026                   0.000010   \n",
      "1312                       0.0         0.000245                   0.000084   \n",
      "1313                       0.0         0.000026                   0.000468   \n",
      "1314                       0.0         0.000293                   0.000242   \n",
      "1315                       0.0         0.000363                   0.000006   \n",
      "1317                       0.0         0.000161                   0.000158   \n",
      "1318                       0.0         0.000314                   0.000125   \n",
      "1319                       0.0         0.000261                   0.000315   \n",
      "1320                       0.0         0.000030                   0.000303   \n",
      "1321                       0.0         0.000259                   0.000047   \n",
      "1322                       0.0         0.000031                   0.000178   \n",
      "1497                       0.0         0.000221                   0.000393   \n",
      "1498                       0.0         0.000312                   0.000006   \n",
      "1500                       0.0         0.000330                   0.000129   \n",
      "1501                       0.0         0.000370                   0.000175   \n",
      "1502                       0.0         0.000029                   0.000024   \n",
      "1503                       0.0         0.000057                   0.000026   \n",
      "1947                       0.0         0.000046                   0.000007   \n",
      "1948                       0.0         0.000029                   0.000046   \n",
      "1949                       0.0         0.000335                   0.000169   \n",
      "1950                       0.0         0.000016                   0.000207   \n",
      "1951                       0.0         0.000035                   0.000550   \n",
      "\n",
      "      LFMM_lasso_0.0_ALL_log10p  rehh_2.0.2_ALL_log10p  Spearmans_ALL_rho  \\\n",
      "700                5.706610e-04               0.000000           0.000098   \n",
      "701                5.894153e-04               0.000000           0.000110   \n",
      "702                6.487677e-05               0.000000           0.000195   \n",
      "704                1.355114e-06               0.000528           0.000165   \n",
      "705                1.499680e-04               0.000000           0.000203   \n",
      "1028               2.085372e-03               0.000098           0.000021   \n",
      "1029               3.755471e-04               0.000000           0.000147   \n",
      "1030               4.849703e-04               0.000211           0.000135   \n",
      "1032               2.108726e-04               0.000073           0.000168   \n",
      "1033               5.096256e-07               0.000171           0.000132   \n",
      "1034               4.810252e-04               0.000174           0.000135   \n",
      "1035               1.236356e-03               0.000081           0.000051   \n",
      "1044               1.590290e-04               0.000038           0.000186   \n",
      "1046               7.068982e-05               0.000049           0.000168   \n",
      "1047               5.502508e-05               0.000000           0.000120   \n",
      "1167               1.016302e-03               0.000502           0.000232   \n",
      "1168               3.488750e-05               0.000272           0.000199   \n",
      "1169               2.580815e-04               0.000000           0.000168   \n",
      "1170               1.256279e-03               0.000497           0.000237   \n",
      "1172               1.962697e-04               0.000000           0.000114   \n",
      "1210               1.268256e-05               0.000458           0.000151   \n",
      "1212               1.776879e-04               0.000000           0.000165   \n",
      "1213               1.005742e-03               0.000442           0.000234   \n",
      "1214               4.282500e-05               0.000949           0.000158   \n",
      "1215               5.214207e-04               0.000000           0.000136   \n",
      "1216               5.214207e-04               0.000583           0.000136   \n",
      "1217               3.091695e-05               0.000182           0.000165   \n",
      "1310               1.385265e-04               0.000325           0.000161   \n",
      "1311               5.089690e-05               0.000000           0.000138   \n",
      "1312               5.031732e-05               0.000044           0.000117   \n",
      "1313               9.710344e-05               0.000000           0.000211   \n",
      "1314               9.025471e-05               0.000715           0.000140   \n",
      "1315               9.148230e-05               0.000036           0.000154   \n",
      "1317               1.434960e-04               0.000000           0.000178   \n",
      "1318               2.350760e-06               0.000759           0.000141   \n",
      "1319               1.160062e-04               0.000740           0.000128   \n",
      "1320               2.743216e-04               0.000000           0.000112   \n",
      "1321               1.317588e-04               0.000182           0.000151   \n",
      "1322               8.648823e-05               0.000000           0.000120   \n",
      "1497               2.345187e-04               0.000607           0.000117   \n",
      "1498               1.740142e-04               0.000098           0.000131   \n",
      "1500               5.234073e-05               0.000023           0.000158   \n",
      "1501               4.277762e-05               0.000335           0.000137   \n",
      "1502               4.928460e-05               0.000000           0.000135   \n",
      "1503               7.306779e-05               0.000000           0.000161   \n",
      "1947               9.839263e-05               0.000000           0.000144   \n",
      "1948               6.477429e-05               0.000000           0.000158   \n",
      "1949               8.184875e-05               0.000123           0.000181   \n",
      "1950               2.065043e-04               0.000000           0.000171   \n",
      "1951               3.260302e-04               0.000000           0.000225   \n",
      "\n",
      "      a_freq_final  pcadapt_3.0.4_PRUNED_log10p  \n",
      "700       0.000087                 4.909901e-04  \n",
      "701       0.000042                 2.984910e-04  \n",
      "702       0.000018                 8.381801e-05  \n",
      "704       0.000383                 1.221812e-04  \n",
      "705       0.000212                 5.497711e-04  \n",
      "1028      0.000630                 2.230236e-03  \n",
      "1029      0.000033                 1.785023e-04  \n",
      "1030      0.000095                 1.585877e-04  \n",
      "1032      0.000048                 3.395948e-05  \n",
      "1033      0.000052                 4.712445e-05  \n",
      "1034      0.000095                 1.558946e-04  \n",
      "1035      0.000617                 2.117630e-03  \n",
      "1044      0.000120                 4.711396e-04  \n",
      "1046      0.000045                 1.238368e-04  \n",
      "1047      0.000018                 1.814002e-04  \n",
      "1167      0.000379                 3.877160e-04  \n",
      "1168      0.000070                 7.996119e-05  \n",
      "1169      0.000028                 1.008162e-04  \n",
      "1170      0.000353                 5.703473e-04  \n",
      "1172      0.000014                 2.497333e-04  \n",
      "1210      0.000165                 1.149078e-04  \n",
      "1212      0.000019                 2.305635e-05  \n",
      "1213      0.000189                 2.122276e-04  \n",
      "1214      0.000166                 1.252330e-04  \n",
      "1215      0.000062                 6.942569e-05  \n",
      "1216      0.000062                 6.942569e-05  \n",
      "1217      0.000262                 3.885791e-04  \n",
      "1310      0.000468                 1.978691e-04  \n",
      "1311      0.000013                 4.483177e-05  \n",
      "1312      0.000154                 1.686253e-04  \n",
      "1313      0.000013                 5.807592e-04  \n",
      "1314      0.000200                 2.230382e-04  \n",
      "1315      0.000311                 2.800524e-05  \n",
      "1317      0.000092                 1.057200e-04  \n",
      "1318      0.000224                 1.460777e-04  \n",
      "1319      0.000169                 2.740999e-04  \n",
      "1320      0.000015                 2.241132e-04  \n",
      "1321      0.000167                 1.880790e-07  \n",
      "1322      0.000729                 1.619174e-04  \n",
      "1497      0.000135                 3.626112e-04  \n",
      "1498      0.000221                 7.708314e-05  \n",
      "1500      0.000246                 1.136234e-04  \n",
      "1501      0.000408                 1.954468e-04  \n",
      "1502      0.000015                 1.481835e-05  \n",
      "1503      0.000030                 3.405959e-05  \n",
      "1947      0.000024                 7.539455e-05  \n",
      "1948      0.000015                 1.446587e-05  \n",
      "1949      0.000491                 2.120150e-04  \n",
      "1950      0.000008                 1.330862e-04  \n",
      "1951      0.000018                 5.145080e-04  \n"
     ]
    }
   ],
   "source": [
    "## Now we need to label all the QTN linked SNPs --- these are defined as any SNP within 200bp of a QTN.\n",
    "## Small and large QTN linked SNPs are labeled differently, and an SNP that is within 200bp of a large and a small\n",
    "## QTN should be labeled as large QTN linked\n",
    "\n",
    "for site in smallQTNs:\n",
    "    lower = site - 200\n",
    "    upper = site + 200\n",
    "    ### use loc to access and change the label of all SNPs between lower and upper, EXCEPT the QTN itself\n",
    "    scaledFeatures.loc[((scaledFeatures['pos'].between(lower, upper)) & (scaledFeatures['pos'] != site)),\n",
    "                      'classLabel'] = 'MT=neut_R=smQTNlink'\n",
    "    \n",
    "for site in largeQTNs:\n",
    "    lower = site - 200\n",
    "    upper = site + 200\n",
    "    ### again, access and change the label using loc\n",
    "    scaledFeatures.loc[(scaledFeatures['pos'].between(lower, upper)) & (scaledFeatures['pos'] != site),\n",
    "                      'classLabel'] = 'MT=neut_R=lgQTNlink'   \n",
    "## Can you think of a way to do this that doesn't use a for loop?\n",
    "\n",
    "# check that the original dataframe got changed\n",
    "print(scaledFeatures[scaledFeatures['classLabel'] == 'MT=neut_R=smQTNlink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the data to separate files, based on the class\n",
    "\n",
    "Almost finished! Let's drop the columns that don't contain statistics, then split up the dataframe based on class_label (sounds like another job for groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          classLabel  Hscan_v1.3_H12  pcadapt_3.0.4_ALL_log10p  \\\n",
      "0  MT=neut_R=neutral             0.0                       0.0   \n",
      "1  MT=neut_R=neutral             0.0                       0.0   \n",
      "2  MT=neut_R=neutral             0.0                       0.0   \n",
      "3  MT=neut_R=neutral             0.0                       0.0   \n",
      "4  MT=neut_R=neutral             0.0                       0.0   \n",
      "\n",
      "   OutFLANK_0.2_He  LFMM_ridge_0.0_ALL_log10p  LFMM_lasso_0.0_ALL_log10p  \\\n",
      "0         0.000313                   0.000121                   0.000008   \n",
      "1         0.000242                   0.000142                   0.000120   \n",
      "2         0.000100                   0.000089                   0.000040   \n",
      "3         0.000017                   0.000085                   0.000312   \n",
      "4         0.000022                   0.000533                   0.000178   \n",
      "\n",
      "   rehh_2.0.2_ALL_log10p  Spearmans_ALL_rho  a_freq_final  \\\n",
      "0                    0.0           0.000137      0.000223   \n",
      "1                    0.0           0.000172      0.000151   \n",
      "2                    0.0           0.000175      0.000054   \n",
      "3                    0.0           0.000136      0.000009   \n",
      "4                    0.0           0.000223      0.000011   \n",
      "\n",
      "   pcadapt_3.0.4_PRUNED_log10p  \n",
      "0                     0.000201  \n",
      "1                     0.000061  \n",
      "2                     0.000083  \n",
      "3                     0.000020  \n",
      "4                     0.000516  \n",
      "(6220, 10)\n"
     ]
    }
   ],
   "source": [
    "## Use the 'drop' function to remove the 'pos' and 'prop' columns\n",
    "## hint: drop can take an argument called \"columns\"\n",
    "scaledFeatures.drop(columns = ['pos', 'prop'], inplace = True)\n",
    "\n",
    "print(scaledFeatures.head())\n",
    "print(scaledFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7f751f374160>\n"
     ]
    }
   ],
   "source": [
    "## use 'groupby' to group the columns based on class label\n",
    "labelGrouped = scaledFeatures.groupby('classLabel')\n",
    "print(labelGrouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'to_csv' function\n",
    "\n",
    "`DataFrame.to_csv(path_or_buf=None, sep=', ', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')`\n",
    "\n",
    "Call on a dataframe object to print the dataframe to a csv file. Ex:\n",
    "\n",
    "`df.to_csv(filename, sep = \" \", index = False, header = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## go through each group, generate a file name, and use the pandas function group.to_csv to print to file\n",
    "\n",
    "for name, group in labelGrouped:\n",
    "# loop through the groupby object:\n",
    "        outfile     = outDir + \"/\" + name + \".fvec\"\n",
    "        outfile     = outfile.replace(\"=\", \"-\")         ## unix doesn't like having '=' in file names\n",
    "        \n",
    "        ## apply the .to_csv function here\n",
    "        group.to_csv(outfile, sep = \" \", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT-delet_R-BS.fvec\t   MT-neut_R-invers.fvec     MT-neut_R-neutral.fvec\n",
      "MT-lgQTN_R-lgQTNlink.fvec  MT-neut_R-lgQTNlink.fvec  MT-neut_R-smQTNlink.fvec\n",
      "MT-neut_R-BS.fvec\t   MT-neut_R-lowRC.fvec      MT-smQTN_R-smQTNlink.fvec\n",
      "MT-neut_R-FarSS.fvec\t   MT-neut_R-NearSS.fvec     MT-sweep_R-NearSS.fvec\n",
      "\n",
      "\n",
      "\n",
      "classLabel Hscan_v1.3_H12 pcadapt_3.0.4_ALL_log10p OutFLANK_0.2_He LFMM_ridge_0.0_ALL_log10p LFMM_lasso_0.0_ALL_log10p rehh_2.0.2_ALL_log10p Spearmans_ALL_rho a_freq_final pcadapt_3.0.4_PRUNED_log10p\n",
      "MT=sweep_R=NearSS 0.0004853543746082687 0.0 5.544337452407637e-05 6.855550384918943e-05 9.133878596663905e-05 0.0 0.000126218561145908 0.0007156107017992282 0.00014585300829671226\n"
     ]
    }
   ],
   "source": [
    "!ls $outDir\n",
    "print(\"\\n\\n\")\n",
    "!head $outfile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
